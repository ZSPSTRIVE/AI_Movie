"""
Cross-Encoder é‡æ’åºæœåŠ¡
æå‡æ£€ç´¢ç²¾åº¦çš„äºŒé˜¶æ®µæ’åº

Author: Jelly Cinema Team
Version: 2.0.0
"""
import logging
from typing import List, Dict, Tuple, Optional
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

from config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


class Reranker:
    """
    Cross-Encoder é‡æ’åºå™¨
    
    ä½¿ç”¨ Cross-Encoder æ¨¡å‹å¯¹ç²—æ’ç»“æœè¿›è¡Œç²¾æ’ï¼Œ
    æ˜¾è‘—æå‡ Top-K ç»“æœçš„ç›¸å…³æ€§ã€‚
    
    å·¥ä½œæµç¨‹:
    ç²—æ’ Top-50 â†’ Cross-Encoder æ‰“åˆ† â†’ ç²¾æ’ Top-5
    """
    
    # æ”¯æŒçš„æ¨¡å‹
    MODELS = {
        "bge-reranker-base": "BAAI/bge-reranker-base",
        "bge-reranker-large": "BAAI/bge-reranker-large",
        "ms-marco": "cross-encoder/ms-marco-MiniLM-L-6-v2",
    }
    
    def __init__(self, model_name: str = "bge-reranker-base"):
        self.model = None
        self.tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model_name = model_name
        self._loaded = False
        
    def load_model(self) -> bool:
        """åŠ è½½æ¨¡å‹"""
        try:
            model_path = self.MODELS.get(self.model_name, self.model_name)
            logger.info(f"ğŸ“¦ Loading reranker model: {model_path}")
            
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
            self.model.to(self.device)
            self.model.eval()
            
            self._loaded = True
            logger.info(f"âœ… Reranker loaded on {self.device}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to load reranker: {e}")
            self._loaded = False
            return False
    
    @property
    def is_ready(self) -> bool:
        return self._loaded and self.model is not None
    
    def compute_score(self, query: str, document: str) -> float:
        """
        è®¡ç®— query-document ç›¸å…³æ€§åˆ†æ•°
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            document: æ–‡æ¡£å†…å®¹
            
        Returns:
            ç›¸å…³æ€§åˆ†æ•° (0-1)
        """
        if not self.is_ready:
            return 0.5
        
        try:
            inputs = self.tokenizer(
                [[query, document]],
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors="pt"
            ).to(self.device)
            
            with torch.no_grad():
                scores = self.model(**inputs).logits.squeeze()
                # Sigmoid å½’ä¸€åŒ–åˆ° 0-1
                if len(scores.shape) == 0:
                    score = torch.sigmoid(scores).item()
                else:
                    score = torch.sigmoid(scores[0]).item()
                return score
                
        except Exception as e:
            logger.warning(f"Rerank score error: {e}")
            return 0.5
    
    def rerank(
        self, 
        query: str, 
        documents: List[Dict], 
        top_k: int = 5,
        content_key: str = "content"
    ) -> List[Dict]:
        """
        å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡Œé‡æ’åº
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£æ˜¯ dict
            top_k: è¿”å› top-k ç»“æœ
            content_key: æ–‡æ¡£å†…å®¹çš„ key
            
        Returns:
            é‡æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        if not self.is_ready or not documents:
            return documents[:top_k]
        
        try:
            # æ‰¹é‡è®¡ç®—åˆ†æ•°
            scored_docs = []
            for doc in documents:
                content = doc.get(content_key, "")
                score = self.compute_score(query, content)
                scored_docs.append({
                    **doc,
                    "rerank_score": score
                })
            
            # æŒ‰ rerank_score é™åºæ’åº
            scored_docs.sort(key=lambda x: x.get("rerank_score", 0), reverse=True)
            
            logger.info(f"ğŸ”„ Reranked {len(documents)} docs, returning top-{top_k}")
            return scored_docs[:top_k]
            
        except Exception as e:
            logger.error(f"âŒ Rerank failed: {e}")
            return documents[:top_k]
    
    def rerank_batch(
        self,
        query: str,
        documents: List[Dict],
        top_k: int = 5,
        content_key: str = "content",
        batch_size: int = 16
    ) -> List[Dict]:
        """
        æ‰¹é‡é‡æ’åº (æ›´é«˜æ•ˆ)
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            documents: æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å› top-k
            content_key: å†…å®¹å­—æ®µå
            batch_size: æ‰¹å¤„ç†å¤§å°
            
        Returns:
            é‡æ’åºåçš„æ–‡æ¡£åˆ—è¡¨
        """
        if not self.is_ready or not documents:
            return documents[:top_k]
        
        try:
            all_scores = []
            
            # åˆ†æ‰¹å¤„ç†
            for i in range(0, len(documents), batch_size):
                batch = documents[i:i + batch_size]
                pairs = [[query, doc.get(content_key, "")] for doc in batch]
                
                inputs = self.tokenizer(
                    pairs,
                    padding=True,
                    truncation=True,
                    max_length=512,
                    return_tensors="pt"
                ).to(self.device)
                
                with torch.no_grad():
                    scores = self.model(**inputs).logits.squeeze(-1)
                    scores = torch.sigmoid(scores).cpu().tolist()
                    
                    # å¤„ç†å•å…ƒç´ æƒ…å†µ
                    if isinstance(scores, float):
                        scores = [scores]
                    
                    all_scores.extend(scores)
            
            # ç»„åˆç»“æœ
            scored_docs = [
                {**doc, "rerank_score": score}
                for doc, score in zip(documents, all_scores)
            ]
            
            # æ’åº
            scored_docs.sort(key=lambda x: x.get("rerank_score", 0), reverse=True)
            
            logger.info(f"ğŸ”„ Batch reranked {len(documents)} docs")
            return scored_docs[:top_k]
            
        except Exception as e:
            logger.error(f"âŒ Batch rerank failed: {e}")
            return documents[:top_k]


# å…¨å±€å•ä¾‹
reranker = Reranker(model_name=settings.reranker_model)


def init_reranker() -> bool:
    """åˆå§‹åŒ–é‡æ’åºå™¨"""
    if settings.enable_reranker:
        return reranker.load_model()
    logger.info("â­ï¸ Reranker disabled by config")
    return False
